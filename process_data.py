import json
import os
from langchain_community.vectorstores import FAISS
from langchain_huggingface import HuggingFaceEmbeddings

class AnimeVectorDB:
    def __init__(self, data_dir="moegirl_data"):
        self.data_dir = data_dir
        self.vector_db_path = "vector_db"
        self.embedding_model = HuggingFaceEmbeddings(model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2")

        if os.path.exists(self.vector_db_path):
            print(f"ğŸ“‚ åŠ è½½å·²æœ‰å‘é‡æ•°æ®åº“: {self.vector_db_path}")
            self.db = FAISS.load_local(self.vector_db_path, self.embedding_model, allow_dangerous_deserialization=True)
        else:
            print("ğŸ“‚ åˆ›å»ºæ–°å‘é‡æ•°æ®åº“...")
            self.create_vector_db()

    def load_json_data(self):
        """åŠ è½½ JSON æ•°æ®"""
        documents = []
        for filename in os.listdir(self.data_dir):
            if filename.endswith(".json"):
                filepath = os.path.join(self.data_dir, filename)
                with open(filepath, "r", encoding="utf-8") as f:
                    data = json.load(f)

                source = data.get("æ¥æº", "æœªçŸ¥æ¥æº")

                # å¤„ç†è§’è‰²ä¿¡æ¯
                for char in data.get("è§’è‰²ä¿¡æ¯", []):
                    char_text = f"{char['è§’è‰²å']} - {char.get('æ‹…å½“', 'æœªçŸ¥è§’è‰²')}"
                    documents.append((char_text, source))

        return documents

    def create_vector_db(self):
        """åˆ›å»º FAISS å‘é‡æ•°æ®åº“"""
        data = self.load_json_data()
        if not data:
            print("âš ï¸ æ²¡æœ‰æ‰¾åˆ°å¯ç”¨çš„ JSON æ•°æ®ï¼Œæ— æ³•åˆ›å»ºå‘é‡æ•°æ®åº“ï¼")
            return

        texts, sources = zip(*data)
        self.db = FAISS.from_texts(texts=texts, embedding=self.embedding_model, metadatas=[{"æ¥æº": src} for src in sources])
        self.db.save_local(self.vector_db_path)
        print("âœ… å‘é‡æ•°æ®åº“å·²åˆ›å»ºå¹¶ä¿å­˜ï¼")

if __name__ == "__main__":
    vector_db = AnimeVectorDB()
