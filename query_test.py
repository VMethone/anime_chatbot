from langchain_community.vectorstores import FAISS
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_ollama import OllamaLLM  # âœ… æ›´æ–° Ollama å¯¼å…¥
import langdetect  # è¯­è¨€æ£€æµ‹

# âœ… ç¡®ä¿ FAISS å‘é‡æ•°æ®åº“æ­£ç¡®åŠ è½½
vector_db = FAISS.load_local(
    "vector_db",
    HuggingFaceEmbeddings(model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"),
    allow_dangerous_deserialization=True  # âœ… è§£å†³åŠ è½½é—®é¢˜
)

# âœ… ä½¿ç”¨æœ¬åœ° LLaMA 3 æ¨¡å‹
llm = OllamaLLM(model="llama3")  # `ollama pull llama3` ç¡®ä¿ä¸‹è½½äº†æ¨¡å‹

while True:
    user_input = input("ğŸ“¢ è¯·è¾“å…¥é—®é¢˜ï¼ˆè¾“å…¥ 'exit' é€€å‡ºï¼‰ï¼š")
    if user_input.lower() == "exit":
        break

    # **1ï¸âƒ£ è¯­è¨€æ£€æµ‹**
    detected_lang = langdetect.detect(user_input)
    print(f"ğŸ” æ£€æµ‹åˆ°è¯­è¨€: {detected_lang}")

    # **2ï¸âƒ£ è¿›è¡Œ FAISS è¯­ä¹‰æœç´¢**
    search_results = vector_db.similarity_search(user_input, k=8)
    context = "\n".join([doc.page_content for doc in search_results])

    # **3ï¸âƒ£ å¦‚æœæ²¡æœ‰åŒ¹é…ç»“æœï¼Œé¿å… AI ä¹±ç­”**
    if not context.strip():
        print("ğŸ¤– AI å›ç­”: æŠ±æ­‰ï¼Œæˆ‘æ²¡æœ‰æ‰¾åˆ°ç›¸å…³ä¿¡æ¯ã€‚")
        continue

    # **4ï¸âƒ£ ç”Ÿæˆ AI å›ç­”**
    prompt = f"""è¯·ç”¨ {'ä¸­æ–‡' if detected_lang.startswith('zh') else 'è‹±æ–‡'} å›ç­”é—®é¢˜ï¼ŒåŸºäºä»¥ä¸‹èƒŒæ™¯çŸ¥è¯†ï¼š
{context}

é—®é¢˜ï¼š{user_input}

è¯·æä¾›å‡†ç¡®ã€è¯¦ç»†çš„å›ç­”ï¼š"""
    answer = llm.invoke(prompt)

    print(f"ğŸ¤– AI å›ç­”:\n{answer}")
