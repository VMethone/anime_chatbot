from langchain_community.vectorstores import FAISS
from langchain_huggingface import HuggingFaceEmbeddings
from langchain.llms import Ollama  # æœ¬åœ° LLaMA 3
import langdetect  # è¯­è¨€æ£€æµ‹

# å…è®¸ FAISS ååºåˆ—åŒ–ï¼ˆç¡®ä¿æ•°æ®åº“æ–‡ä»¶æ˜¯è‡ªå·±ç”Ÿæˆçš„ï¼‰
vector_db = FAISS.load_local(
    "vector_db",
    HuggingFaceEmbeddings(model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"),
    allow_dangerous_deserialization=True
)

# åŠ è½½æœ¬åœ° LLaMA 3
llm = Ollama(model="llama3")  # ç¡®ä¿ä½ å·²ä¸‹è½½ `ollama pull llama3`

while True:
    user_input = input("ğŸ“¢ è¯·è¾“å…¥é—®é¢˜ï¼ˆè¾“å…¥ 'exit' é€€å‡ºï¼‰ï¼š")
    if user_input.lower() == "exit":
        break

    # æ£€æµ‹è¾“å…¥è¯­è¨€
    detected_lang = langdetect.detect(user_input)
    print(f"ğŸ” æ£€æµ‹åˆ°è¯­è¨€: {detected_lang}")

    # è¿›è¡Œ FAISS ç›¸ä¼¼æ€§æœç´¢ï¼ˆå¢åŠ  `k=8` è·å–æ›´å¤šèƒŒæ™¯ä¿¡æ¯ï¼‰
    search_results = vector_db.similarity_search(user_input, k=8)
    context = "\n".join([doc.page_content for doc in search_results])

    # å¦‚æœ `FAISS` ç»“æœä¸ºç©ºï¼Œç›´æ¥å›ç­” "æˆ‘ä¸çŸ¥é“"
    if not context.strip():
        print("ğŸ¤– AI å›ç­”: æˆ‘ä¸çŸ¥é“ã€‚")
        continue

    # è®© AI ç”Ÿæˆè¯¦ç»†å›ç­”
    prompt = f"""è¯·ä½¿ç”¨{ 'ä¸­æ–‡' if detected_lang.startswith('zh') else 'è‹±æ–‡' }è¯¦ç»†å›ç­”ä»¥ä¸‹é—®é¢˜ã€‚
ä½ çš„å›ç­”å¿…é¡»åŸºäºæä¾›çš„èƒŒæ™¯çŸ¥è¯†ï¼Œä¸è¦ç¼–é€ å†…å®¹ã€‚è¯·å°½å¯èƒ½æä¾›å®Œæ•´çš„ä¿¡æ¯ï¼ŒåŒ…æ‹¬äººç‰©èƒŒæ™¯ã€å‰§æƒ…ç›¸å…³å†…å®¹ç­‰ã€‚è¦åŒ…æ‹¬å°½å¯èƒ½å¤šçš„ç»†èŠ‚ã€‚

èƒŒæ™¯çŸ¥è¯†ï¼š
{context}

é—®é¢˜ï¼š{user_input}

è¯·æä¾›è¯¦ç»†å›ç­”ï¼š
"""

    answer = llm.invoke(prompt)

    print(f"ğŸ¤– AI å›ç­”:\n{answer}")
